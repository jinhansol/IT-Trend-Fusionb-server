# backend/services/dev_scraper.py
# flake8: noqa

"""
üî• Hybrid Dev Scraper
1. OKKY: Selenium (ÏïàÏ†ïÏÑ±) + ThreadPool (ÏÜçÎèÑ)
2. Dev.to: API (ÏïàÏ†ïÏÑ± & ÏÜçÎèÑ) + ThreadPool (AI ÏöîÏïΩ Í∞ÄÏÜç)
"""

import os
import time
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from dotenv import load_dotenv
from openai import OpenAI
from concurrent.futures import ThreadPoolExecutor, as_completed

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ================================================================
# üü¢ Selenium Driver (OKKYÏö©)
# ================================================================
def create_driver():
    options = Options()
    options.add_argument("--headless=new") 
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/127.0.0.1 Safari/537.36"
    )

    driver = webdriver.Chrome(options=options)
    
    driver.execute_cdp_cmd(
        "Page.addScriptToEvaluateOnNewDocument",
        {
            "source": """
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
            """
        },
    )
    return driver

# ================================================================
# üß† AI ÏöîÏïΩ
# ================================================================
def summarize_text(title, content=None, author=None):
    content = content or ""
    prompt = f"""
    ÎãπÏã†ÏùÄ Í∞úÎ∞úÏûê Ïª§ÎÆ§ÎãàÌã∞ Í∏ÄÏùÑ ÏöîÏïΩÌïòÎäî Ï†ÑÎ¨∏ ÏöîÏïΩ ÏãúÏä§ÌÖúÏûÖÎãàÎã§.

    [Ï†úÎ™©]
    {title}

    [ÎÇ¥Ïö©]
    {content}

    Îã§Ïùå Í∑úÏπôÏúºÎ°ú 3~4Î¨∏Ïû• ÌïúÍµ≠Ïñ¥ ÏöîÏïΩÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî:
    - Í∏∞Ïà†Ï†Å ÎÇ¥Ïö©ÏùÑ Ï§ëÏã¨ÏúºÎ°ú ÌïµÏã¨ ÏöîÏïΩ
    - ÎÑàÎ¨¥ Ïû•Ìô©ÌïòÍ≤å Ïì∞ÏßÄ Îßê Í≤É
    - ÏûêÏó∞Ïä§Îü¨Ïö¥ ÌïúÍµ≠Ïñ¥ ÏÇ¨Ïö©
    - HTML, ÏΩîÎìú Î∏îÎ°ù Îì± Ï†úÍ±∞
    """
    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        print(f"‚ö†Ô∏è AI Summary Error: {e}")
        return title

# ================================================================
# üõ†Ô∏è ÏûëÏóÖÏûê Ìï®Ïàò (Worker)
# ================================================================
def process_okky_card(card_html):
    try:
        if isinstance(card_html, str):
            card = BeautifulSoup(card_html, "html.parser")
        else:
            card = card_html

        title_el = card.select_one("h3 a")
        if not title_el: return None

        title = title_el.text.strip()
        link = title_el.get("href")
        url = "https://okky.kr" + link if link.startswith("/") else link
        source_id = link.split("/")[-1]

        author_el = card.select_one('a[href^="/users/"]')
        author = author_el.text.strip() if author_el else "Anonymous"

        view_count = 0
        view_el = card.find("span", string=lambda x: x and "Ï°∞Ìöå" in x)
        if view_el:
            strong = view_el.find("strong")
            if strong:
                view_count = int(strong.text.strip())

        time_el = card.select_one("time")
        published_at = time_el["datetime"] if time_el else None

        summary = summarize_text(title, content=None, author=author)

        return {
            "source": "okky",
            "source_id": source_id,
            "title": title,
            "url": url,
            "author": author,
            "summary": summary,
            "tags": [],
            "like_count": 0,
            "comment_count": 0,
            "view_count": view_count,
            "published_at": published_at,
            "crawled_at": None,
        }
    except Exception as e:
        print(f"Error processing OKKY item: {e}")
        return None

def process_devto_item(p):
    try:
        title = p["title"]
        url = p["url"]
        author = p["user"]["username"]
        description = p.get("description") or p.get("title")

        summary = summarize_text(title, content=description, author=author)

        return {
            "source": "devto",
            "source_id": str(p["id"]),
            "title": title,
            "url": url,
            "author": author,
            "summary": summary,
            "tags": p.get("tag_list", []),
            "like_count": p.get("public_reactions_count", 0),
            "comment_count": p.get("comments_count", 0),
            "view_count": p.get("page_views_count", 0),
            "published_at": p["published_at"],
            "crawled_at": None,
        }
    except Exception as e:
        print(f"Error processing Dev.to item: {e}")
        return None

# ================================================================
# üîµ OKKY ÌÅ¨Î°§ÎßÅ (Ìï®ÏàòÎ™Ö ÏàòÏ†ï: fetch_okky_latest -> crawl_okky)
# ================================================================
def crawl_okky(limit=20):
    print("üöÄ [OKKY] Starting Selenium...")
    driver = create_driver()
    url = "https://okky.kr/articles/tech?sort=latest"

    try:
        driver.get(url)
        time.sleep(2)

        page_source = driver.page_source
        soup = BeautifulSoup(page_source, "html.parser")
        driver.quit() 
        print("‚úÖ [OKKY] Page Source Fetched. Processing Items...")

        cards = soup.select("div.flex.gap-4")[:limit]
        card_htmls = [str(card) for card in cards]

        results = []
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(process_okky_card, html) for html in card_htmls]
            
            for future in as_completed(futures):
                item = future.result()
                if item:
                    results.append(item)
        
        return results

    except Exception as e:
        print(f"‚ùå OKKY Selenium Error: {e}")
        try: driver.quit()
        except: pass
        return []

# ================================================================
# üü£ Dev.to (Ìï®ÏàòÎ™Ö ÏàòÏ†ï: fetch_devto_latest -> crawl_devto)
# ================================================================
def crawl_devto(limit=20, tag=None):
    base_url = "https://dev.to/api/articles"
    params = {"per_page": limit}
    if tag: params["tag"] = tag

    try:
        res = requests.get(base_url, params=params, timeout=10)
        if res.status_code != 200: return []

        arr = res.json()
        results = []

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(process_devto_item, p) for p in arr]
            
            for future in as_completed(futures):
                item = future.result()
                if item:
                    results.append(item)

        return results
        
    except Exception as e:
        print(f"‚ùå Dev.to Crawling Error: {e}")
        return []