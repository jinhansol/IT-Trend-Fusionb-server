# backend/services/career_service.py
# flake8: noqa

import json
from collections import Counter
from datetime import datetime, timedelta
from sqlalchemy.orm import Session

from database.mariadb import SessionLocal
from database.models import CareerJob, UserProfile


# ==========================================
# ğŸ” ì¸ì‹í•  ê¸°ìˆ  í‚¤ì›Œë“œ (ì§ë¬´ ì¶”ì¶œìš©)
# ==========================================
TECH_KEYWORDS = [
    "Python", "React", "Node", "TypeScript", "Vue",
    "Next.js", "Java", "Spring", "Django", "Flutter",
    "AWS", "Kubernetes", "Docker", "AI", "ML", "Data",
]


# ==========================================
# ğŸ§© ì œëª©ì—ì„œ ê¸°ìˆ  ìŠ¤í‚¬ ì¶”ì¶œ
# ==========================================
def extract_skills_from_title(title: str):
    found = []
    if not title:
        return found

    lower_title = title.lower()
    for skill in TECH_KEYWORDS:
        if skill.lower() in lower_title:
            found.append(skill)

    return found


# ==========================================
# ğŸ“Š 8ì£¼ê°„ ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„
# ==========================================
def get_weekly_tech_trends(db: Session, weeks: int = 8):
    end_date = datetime.now()
    start_date = end_date - timedelta(weeks=weeks)

    jobs = (
        db.query(CareerJob)
        .filter(CareerJob.posted_date >= start_date)
        .all()
    )

    weekly_counter = Counter()

    for job in jobs:
        skills = extract_skills_from_title(job.title)
        weekly_counter.update(skills)

    trend_list = [
        {"skill": skill, "count": count}
        for skill, count in weekly_counter.most_common()
    ]

    return trend_list


# ==========================================
# ğŸ¯ ì‚¬ìš©ì ê´€ì‹¬ ê¸°ìˆ  ê°€ì ¸ì˜¤ê¸°
# ==========================================
def get_user_skills(user: UserProfile):
    if not user:
        return []

    raw = user.tech_stack

    # JSON ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš°
    if isinstance(raw, list):
        return [s for s in raw if isinstance(s, str) and s.strip()]

    # ë¬¸ìì—´ì¼ ê²½ìš°: "Python, React"
    if isinstance(raw, str):
        return [s.strip() for s in raw.split(",") if s.strip()]

    return []


# ==========================================
# ğŸ¯ ì‚¬ìš©ì ë§ì¶¤ ì±„ìš© ì¶”ì²œ
# ==========================================
def get_recommended_jobs(db: Session, skills: list, limit: int = 20):
    if not skills:
        return (
            db.query(CareerJob)
            .order_by(CareerJob.posted_date.desc())
            .limit(limit)
            .all()
        )

    query = db.query(CareerJob)
    filters = []

    for skill in skills:
        if skill:
            filters.append(CareerJob.title.ilike(f"%{skill}%"))

    if filters:
        query = query.filter(*filters)

    return (
        query.order_by(CareerJob.posted_date.desc())
        .limit(limit)
        .all()
    )


# =================================================
# ğŸ’¾ DB ì €ì¥ ë¡œì§ â€” í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ CareerJobì— ì €ì¥
# =================================================
def save_job_posting(db: Session, job_data: dict):
    """
    í¬ë¡¤ë§ ê²°ê³¼(dict)ë¥¼ CareerJob í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    í•˜ë“œì½”ë”© ì—†ìŒ. ëª©ì—… ì—†ìŒ.
    job_data ì˜ˆ:
    {
        'title': 'Python ê°œë°œì',
        'company': 'ì‚¼ì„±ì „ì',
        'location': 'ì„œìš¸ ê°•ë‚¨êµ¬',
        'tags': ['Python', 'AI'],
        'url': 'https://www.jobkorea.co.kr/...',
        'source': 'JobKorea'
    }
    """

    # 1) URL ê¸°ì¤€ ì¤‘ë³µ ì²´í¬
    exists = (
        db.query(CareerJob)
        .filter(CareerJob.url == job_data["url"])
        .first()
    )

    if exists:
        return False  # ì´ë¯¸ ì €ì¥ë¨

    job = CareerJob(
        title=job_data.get("title"),
        company=job_data.get("company"),
        location=job_data.get("location"),
        tags=json.dumps(job_data.get("tags", []), ensure_ascii=False),
        url=job_data.get("url"),
        source=job_data.get("source", "Unknown"),
        posted_date=datetime.utcnow(),
        created_at=datetime.utcnow(),
    )

    try:
        db.add(job)
        db.commit()
        return True
    except:
        db.rollback()
        return False


# =================================================
# ğŸ’¾ í¬ë¡¤ë§ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ë¥¼ CareerJob í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” Pipeline
# =================================================
def save_crawled_jobs(results: list[dict]):
    """
    JobKorea / ì‚¬ëŒì¸ / ê¸°íƒ€ í¬ë¡¤ëŸ¬ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°(dict ë¦¬ìŠ¤íŠ¸)ë¥¼
    CareerJob í…Œì´ë¸”ì— ì¼ê´„ ì €ì¥í•˜ëŠ” pipeline.
    """
    db = SessionLocal()
    saved = 0

    for job in results:
        ok = save_job_posting(db, job)
        if ok:
            saved += 1

    db.close()
    print(f"ğŸ’¾ CareerJob ì €ì¥ ì™„ë£Œ: {saved}ê°œ / ì´ {len(results)}ê°œ")


# ======================
# ì‚¬ìš© ì˜ˆì‹œ (í¬ë¡¤ë§ íŒŒì¼ì—ì„œ í˜¸ì¶œ)
# ======================
"""
from services.jobkorea_crawler import crawl_jobkorea
from services.career_service import save_crawled_jobs

results = crawl_jobkorea("Python")
save_crawled_jobs(results)
"""
