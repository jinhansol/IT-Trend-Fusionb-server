# flake8: noqa
"""ğŸš€ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ + AI ìš”ì•½ + ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ íƒœê¹… + DB ì €ì¥ í†µí•©"""

import os
import json
import requests
import feedparser
from datetime import datetime
from urllib.parse import urljoin
from dotenv import load_dotenv
from openai import OpenAI

from database.mariadb import SessionLocal
from database.models import NewsFeed

load_dotenv()

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)


# -----------------------------
# ğŸ”§ URL í†µí•© í•¨ìˆ˜
# -----------------------------
def extract_url(item: dict) -> str:
    """Google/Naver í˜¼í•© êµ¬ì¡°ì—ì„œ ì•ˆì „í•˜ê²Œ URLë§Œ ë½‘ì•„ëƒ„"""
    return (item.get("url") or item.get("link") or "").strip()


# -----------------------------
# ğŸ§  LLM ìš”ì•½
# -----------------------------
def summarize_text(title: str) -> str:
    if not title:
        return ""
    try:
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ì„ í•œêµ­ì–´ë¡œ 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜:\n\n{title}",
                }
            ],
            temperature=0.4,
        )
        return res.choices[0].message.content.strip()
    except Exception:
        return ""


# -----------------------------
# ğŸ§  LLM ì¹´í…Œê³ ë¦¬ / í‚¤ì›Œë“œ ì¶”ì¶œ
# -----------------------------
BASE_CATEGORIES = [
    "AI / ML",
    "Frontend",
    "Backend",
    "Cloud",
    "DevOps",
    "Security",
    "Data / Analytics",
    "Mobile",
    "Game",
    "Open Source",
    "Other",
]


def extract_tags_with_llm(title: str, summary: str) -> dict:
    """
    LLMìœ¼ë¡œë¶€í„° ì¹´í…Œê³ ë¦¬(1~2ê°œ) + í‚¤ì›Œë“œ(5~10ê°œ)ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°›ì•„ì˜´.
    ì¶œë ¥ì´ ì½”ë“œë¸”ë¡/í…ìŠ¤íŠ¸ ì„ì—¬ ìˆì–´ë„ ìµœëŒ€í•œ JSONë§Œ íŒŒì‹±.
    """
    try:
        prompt = f"""
ë‹¤ìŒ IT/ê¸°ìˆ  ë‰´ìŠ¤ì˜ ì£¼ì œ ì¹´í…Œê³ ë¦¬ì™€ ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜.

- category: ì•„ë˜ ë¦¬ìŠ¤íŠ¸ì—ì„œ 1~2ê°œë§Œ ê³ ë¥´ê³ , ì—†ìœ¼ë©´ "Other" ì‚¬ìš©
{BASE_CATEGORIES}

- keywords: 5~10ê°œ, í•œêµ­ì–´/ì˜ì–´ ì„ì—¬ë„ ë˜ê³ , í•œ ë‹¨ì–´ ë˜ëŠ” ì§§ì€ êµ¬ë¬¸ ìœ„ì£¼

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´.
í˜•ì‹ ì˜ˆì‹œ:
{{
  "category": ["AI / ML"],
  "keywords": ["ì±—ë´‡", "LLM", "ì˜¤í”ˆAI", "ìƒì„±í˜• AI", "ëª¨ë¸ ì—…ë°ì´íŠ¸"]
}}

ë‰´ìŠ¤ ì œëª©: {title}
ë‰´ìŠ¤ ìš”ì•½: {summary}
"""
        res = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
        )
        raw = res.choices[0].message.content.strip()

        # ì½”ë“œë¸”ë¡/í…ìŠ¤íŠ¸ ì„ì¸ ê²½ìš° ëŒ€ë¹„í•´ì„œ { ... } ë¶€ë¶„ë§Œ ì¶”ì¶œ
        start = raw.find("{")
        end = raw.rfind("}")
        if start == -1 or end == -1:
            return {"category": [], "keywords": []}

        json_str = raw[start : end + 1]
        data = json.loads(json_str)

        cats = data.get("category") or data.get("categories") or []
        kws = data.get("keywords") or []

        # ë¬¸ìì—´ í•˜ë‚˜ë§Œ ì˜¨ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°
        if isinstance(cats, str):
            cats = [cats]
        if isinstance(kws, str):
            kws = [kws]

        # ë² ì´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì™¸ì˜ ê°’ì€ Otherë¡œ ì²˜ë¦¬
        normalized_cats = []
        for c in cats:
            c = str(c).strip()
            if not c:
                continue
            if c in BASE_CATEGORIES:
                normalized_cats.append(c)
            else:
                normalized_cats.append("Other")

        if not normalized_cats:
            normalized_cats = ["Other"]

        # í‚¤ì›Œë“œëŠ” ê³µë°± ì œê±° + ì¤‘ë³µ ì œê±°
        clean_kws = []
        seen = set()
        for k in kws:
            k = str(k).strip()
            if not k or k.lower() in seen:
                continue
            seen.add(k.lower())
            clean_kws.append(k)

        return {
            "category": normalized_cats,
            "keywords": clean_kws[:10],  # ìµœëŒ€ 10ê°œ
        }

    except Exception:
        return {"category": [], "keywords": []}


# -----------------------------
# ğŸŒ Google ë‰´ìŠ¤
# -----------------------------
def fetch_google_news(limit: int = 4):
    url = "https://news.google.com/rss/search?q=technology&hl=en&gl=US&ceid=US:en"
    feed = feedparser.parse(url)

    results = []
    for entry in feed.entries[:limit]:
        link = urljoin("https://news.google.com/", entry.link)

        published = (
            datetime(*entry.published_parsed[:6])
            if hasattr(entry, "published_parsed")
            else datetime.utcnow()
        )

        title = entry.title
        summary = summarize_text(title)

        tags = extract_tags_with_llm(title, summary)

        results.append(
            {
                "source": "Google News",
                "title": title,
                "summary": summary,
                "url": link,
                "published_at": published,
                "category": tags["category"],
                "keywords": tags["keywords"],
            }
        )

    return results


# -----------------------------
# ğŸ‡°ğŸ‡· Naver ë‰´ìŠ¤
# -----------------------------
def fetch_naver_news(keyword: str = "IT", limit: int = 4):
    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": NAVER_CLIENT_ID,
        "X-Naver-Client-Secret": NAVER_CLIENT_SECRET,
    }
    params = {"query": keyword, "display": limit, "sort": "date"}

    res = requests.get(url, headers=headers, params=params, timeout=8)
    items = res.json().get("items", [])

    results = []
    for item in items:
        clean_title = item["title"].replace("<b>", "").replace("</b>", "")

        try:
            pub = datetime.strptime(item["pubDate"], "%a, %d %b %Y %H:%M:%S %z")
            published = pub.astimezone().replace(tzinfo=None)
        except Exception:
            published = datetime.utcnow()

        summary = summarize_text(clean_title)
        tags = extract_tags_with_llm(clean_title, summary)

        results.append(
            {
                "source": "Naver News",
                "title": clean_title,
                "summary": summary,
                "url": item["link"],
                "published_at": published,
                "category": tags["category"],
                "keywords": tags["keywords"],
            }
        )

    return results


# -----------------------------
# ğŸ§© í†µí•© + ì¤‘ë³µ ì œê±°
# -----------------------------
def get_latest_news(keyword: str = "IT", limit: int = 8):
    google = fetch_google_news(limit // 2)
    naver = fetch_naver_news(keyword, limit // 2)

    news = google + naver

    seen = set()
    unique = []

    for n in news:
        url = extract_url(n)
        key = (n["title"].lower(), url)

        if key not in seen:
            seen.add(key)
            unique.append(n)

    return unique


# -----------------------------
# ğŸ’¾ DB ì €ì¥
# -----------------------------
def save_news_to_db(keyword: str = "IT"):
    """
    - ìµœì‹  ë‰´ìŠ¤ ìˆ˜ì§‘ (Google + Naver)
    - ìš”ì•½ + ì¹´í…Œê³ ë¦¬ + í‚¤ì›Œë“œ íƒœê¹…
    - news_feed í…Œì´ë¸”ì— ì¤‘ë³µ ì—†ì´ ì €ì¥
    """
    db = SessionLocal()

    try:
        news_items = get_latest_news(keyword)

        existing = db.query(NewsFeed.title, NewsFeed.source, NewsFeed.url).all()
        existing_set = {(t.lower(), s, u) for t, s, u in existing}

        added = 0
        for n in news_items:
            key = (n["title"].lower(), n["source"], n["url"])
            if key in existing_set:
                continue

            record = NewsFeed(
                title=n["title"],
                summary=n["summary"],
                source=n["source"],
                url=n["url"],
                published_at=n["published_at"],
                # LLM íƒœê¹… ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ë¡œ ì €ì¥
                content=None,
                category=json.dumps(n.get("category", []), ensure_ascii=False),
                keywords=json.dumps(n.get("keywords", []), ensure_ascii=False),
            )

            db.add(record)
            added += 1

        db.commit()
        print(f"ğŸ’¾ {added}ê°œ ë‰´ìŠ¤ ì €ì¥ë¨")

    except Exception as e:
        db.rollback()
        print("âŒ DB ì €ì¥ ì˜¤ë¥˜:", e)

    finally:
        db.close()
