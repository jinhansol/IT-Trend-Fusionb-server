# services/velog_scraper.py
# flake8: noqa

import re
from bs4 import BeautifulSoup
from utils.http import safe_request


BASE = "https://velog.io"


# --------------------------------------------------------------------
# ğŸ“Œ HTML ê¸°ë°˜: Velog Trending ë¶ˆëŸ¬ì˜¤ê¸°
# --------------------------------------------------------------------
def fetch_velog_trending_html():
    """
    Velog Trending í˜ì´ì§€ë¥¼ HTML ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜.
    - ì œëª©
    - URL
    - ìš”ì•½ (ë³¸ë¬¸ ì¼ë¶€)
    """
    url = f"{BASE}/?sort=trending"

    res = safe_request(url)
    if not res:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    posts = []

    for item in soup.select("div.post-card"):
        title_tag = item.select_one("h2")
        link_tag = item.select_one("a")

        if not title_tag or not link_tag:
            continue

        url = BASE + link_tag["href"]
        title = title_tag.text.strip()

        # ìš”ì•½ì€ ì˜ë ¤ ìˆëŠ” ë³¸ë¬¸ ì¼ë¶€
        summary_tag = item.select_one("p.preview")
        summary = summary_tag.text.strip() if summary_tag else ""

        posts.append({
            "title": title,
            "url": url,
            "summary": summary,
        })

    return posts


# --------------------------------------------------------------------
# ğŸ“Œ HTML ê¸°ë°˜: Velog ì¸ê¸° íƒœê·¸
# --------------------------------------------------------------------
def fetch_velog_tags_html():
    """
    Velog ì¸ê¸° íƒœê·¸ í˜ì´ì§€ì—ì„œ íƒœê·¸ + count ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜.
    """
    url = f"{BASE}/tags"

    res = safe_request(url)
    if not res:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    tags = []

    for tag_item in soup.select("div.tag-item"):
        name_tag = tag_item.select_one("h4")
        count_tag = tag_item.select_one("span.count")

        if not name_tag:
            continue

        tag = name_tag.text.strip()
        count = int(re.sub(r"[^0-9]", "", count_tag.text)) if count_tag else 0

        tags.append({
            "tag": tag,
            "count": count,
        })

    return tags


# --------------------------------------------------------------------
# ğŸ“Œ HTML ê¸°ë°˜: íŠ¹ì • íƒœê·¸ ì¸ê¸°ê¸€
# --------------------------------------------------------------------
def fetch_velog_by_tag_html(tag: str):
    """
    Velog íŠ¹ì • íƒœê·¸ í˜ì´ì§€ì—ì„œ ì¸ê¸° ê¸€ ëª©ë¡ì„ ê°€ì ¸ì˜´.
    """
    url = f"{BASE}/tags/{tag}"

    res = safe_request(url)
    if not res:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    posts = []

    for item in soup.select("div.post-card"):
        title_tag = item.select_one("h2")
        link_tag = item.select_one("a")

        if not title_tag or not link_tag:
            continue

        posts.append({
            "title": title_tag.text.strip(),
            "url": BASE + link_tag["href"],
            "summary": item.select_one("p.preview").text.strip()
            if item.select_one("p.preview") else "",
        })

    return posts


# --------------------------------------------------------------------
# ğŸ“Œ RSS ê¸°ë°˜: Velog íŠ¹ì • ìœ ì € ë¸”ë¡œê·¸ ê¸€
# --------------------------------------------------------------------
def fetch_velog_rss(username: str):
    """
    https://velog.io/rss/@ì‚¬ìš©ìëª…
    â†’ RSS ê¸°ë°˜ìœ¼ë¡œ ê¸€ ëª©ë¡ íŒŒì‹±
    """
    rss_url = f"{BASE}/rss/@{username}"

    res = safe_request(rss_url)
    if not res:
        return []

    soup = BeautifulSoup(res.text, "xml")
    items = soup.find_all("item")

    results = []

    for item in items:
        title = item.title.text if item.title else ""
        link = item.link.text if item.link else ""
        desc = item.description.text if item.description else ""

        # descriptionì—ì„œ HTML ì œê±°
        summary = BeautifulSoup(desc, "html.parser").text[:150]

        results.append({
            "title": title,
            "url": link,
            "summary": summary,
        })

    return results
