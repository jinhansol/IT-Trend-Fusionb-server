from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time

def crawl_saramin(keyword="Python", max_results=20):
    print("[Saramin] Selenium í¬ë¡¤ë§ ì‹œì‘...")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ”§ Selenium ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("user-agent=Mozilla/5.0")

    driver = webdriver.Chrome(options=options)

    url = f"https://www.saramin.co.kr/zf_user/search?searchword={keyword}"
    driver.get(url)
    time.sleep(2)  # JS ë Œë”ë§ ì‹œê°„

    # ìŠ¤í¬ë¡¤ ë‹¤ìš´ (ê³µê³  ë” ë¡œë“œë¨)
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)

    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    driver.quit()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ğŸ¯ ê³µê³  ì¹´ë“œ ì„ íƒ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    job_cards = soup.select("div.item_recruit")
    print(f"[Saramin] ê°ì§€ëœ ê³µê³  ìˆ˜: {len(job_cards)}")

    results = []

    for job in job_cards[:max_results]:
        try:
            title_tag = job.select_one("h2.job_tit > a")
            company_tag = job.select_one("strong.corp_name > a")
            condition_tag = job.select_one("div.job_condition")

            title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"
            company = company_tag.get_text(strip=True) if company_tag else "íšŒì‚¬ëª… ì—†ìŒ"

            info = (
                " Â· ".join([span.get_text(strip=True) for span in condition_tag.select("span")])
                if condition_tag else ""
            )

            link = (
                "https://www.saramin.co.kr" + title_tag["href"]
                if title_tag and title_tag.has_attr("href")
                else ""
            )

            results.append({
                "title": title,
                "company": company,
                "info": info,
                "url": link,
                "source": "Saramin",
            })
        except Exception as e:
            print("[Saramin Parse Error]", e)

    print(f"[Saramin] ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê°œ")
    return results
