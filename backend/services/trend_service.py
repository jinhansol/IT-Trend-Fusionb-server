# backend/services/trend_service.py
# flake8: noqa
"""
ðŸ§  Trend Service â€” ì‚¬ìš©ìž ê´€ì‹¬ ê¸°ë°˜ + ì „ì²´ ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ìš”ì•½
"""

import os
import asyncio
import json
from datetime import datetime

from openai import OpenAI
from sqlalchemy import or_
from database.mariadb import SessionLocal
from database.models import UserProfile, TechTrend, NewsFeed

# ðŸ”‘ OpenAI í´ë¼ì´ì–¸íŠ¸ (openai>=1.x ë°©ì‹)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ---------------------------------------------------------
# ðŸ§© íŠ¸ë Œë“œ DB ì €ìž¥
# ---------------------------------------------------------
def save_trend_to_db(keyword: str, summary: str):
    db = SessionLocal()
    try:
        db.add(
            TechTrend(
                keyword=keyword,
                summary=summary,
                fetched_at=datetime.utcnow(),
            )
        )
        db.commit()
        print(f"âœ… '{keyword}' íŠ¸ë Œë“œ ì €ìž¥ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ íŠ¸ë Œë“œ ì €ìž¥ ì‹¤íŒ¨: {e}")
        db.rollback()
    finally:
        db.close()


# ---------------------------------------------------------
# ðŸ§  ê³µí†µ: GPTì—ê²Œ íŠ¸ë Œë“œ ìš”ì•½ ìš”ì²­
# ---------------------------------------------------------
def generate_trend_summary(keyword: str, titles: list[str]) -> str:
    if not titles:
        return ""

    text = f"[{keyword}] ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ ì œëª©:\n" + "\n".join(titles)

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ IT ê¸°ìˆ  íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.",
            },
            {
                "role": "user",
                "content": f"{text}\n\nìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ íŠ¸ë Œë“œë¥¼ 3~4ë¬¸ìž¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.",
            },
        ],
        max_tokens=200,
    )

    return res.choices[0].message.content.strip()


# ---------------------------------------------------------
# ðŸ” ì‚¬ìš©ìž ê´€ì‹¬ì‚¬ ê¸°ë°˜ ì¶”ì²œ (APIì—ì„œ í˜¸ì¶œ)
# ---------------------------------------------------------
async def get_trend_recommendations(user_id: int):
    """
    íŠ¹ì • ì‚¬ìš©ìž ê´€ì‹¬ì‚¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë Œë“œë¥¼ ìƒì„±í•¨.
    (ìŠ¤ì¼€ì¤„ëŸ¬ìš© ì•„ë‹˜)
    """
    db = SessionLocal()

    # 1) ì‚¬ìš©ìž ì •ë³´
    user = db.query(UserProfile).filter(UserProfile.id == user_id).first()
    if not user:
        db.close()
        return {"message": "âŒ ì‚¬ìš©ìžë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    interests = user.interest_topics or []
    if not interests:
        db.close()
        return {"message": "â„¹ ê´€ì‹¬ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."}

    results = []

    # 2) í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ê²€ìƒ‰ â†’ ìµœê·¼ 3ê°œ
    for keyword in interests:
        news_items = (
            db.query(NewsFeed)
            .filter(
                or_(
                    NewsFeed.title.ilike(f"%{keyword}%"),
                    NewsFeed.summary.ilike(f"%{keyword}%"),
                    NewsFeed.keywords.ilike(f"%{keyword}%"),
                )
            )
            .order_by(NewsFeed.published_at.desc())
            .limit(3)
            .all()
        )

        titles = [item.title for item in news_items]
        if not titles:
            continue

        try:
            summary = generate_trend_summary(keyword, titles)
            if summary:
                save_trend_to_db(keyword, summary)
                results.append({"keyword": keyword, "summary": summary})
        except Exception as e:
            print(f"âš ï¸ {keyword} ìš”ì•½ ì‹¤íŒ¨: {e}")
            results.append(
                {"keyword": keyword, "summary": f"ìš”ì•½ ì‹¤íŒ¨: {e}"}
            )

    db.close()
    return {"recommendations": results}


# ---------------------------------------------------------
# ðŸ”Ž ì „ì—­ íŠ¸ë Œë“œìš© í‚¤ì›Œë“œ íŒŒì‹± ìœ í‹¸
#   (n.keywordsê°€ '["Microsoft", "AI", ...]' í˜•íƒœì—¬ë„ ìž˜ ì²˜ë¦¬)
# ---------------------------------------------------------
def parse_keywords(raw: str) -> list[str]:
    if not raw:
        return []

    # 1) JSON ë¦¬ìŠ¤íŠ¸ë¡œ ì €ìž¥ëœ ê²½ìš°
    try:
        data = json.loads(raw)
        if isinstance(data, list):
            return [
                k.strip()
                for k in data
                if isinstance(k, str) and len(k.strip()) > 1
            ]
    except Exception:
        pass

    # 2) ê·¸ ì™¸ â†’ ì‰¼í‘œ ê¸°ì¤€ íŒŒì‹±
    return [
        part.strip()
        for part in raw.split(",")
        if len(part.strip()) > 1
    ]


def news_has_keyword(news: NewsFeed, keyword: str) -> bool:
    if not news.keywords:
        return False

    try:
        kws = parse_keywords(news.keywords)
        return any(k == keyword for k in kws)
    except Exception:
        return keyword in news.keywords


# ---------------------------------------------------------
# ðŸŒ ì „ì²´ ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ (ìŠ¤ì¼€ì¤„ëŸ¬ ì „ìš©)
# ---------------------------------------------------------
async def update_global_trends():
    """
    user_id ì—†ì´ â€” ì „ì²´ ë‰´ìŠ¤ DBë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ìƒì„±í•˜ì—¬ ì €ìž¥.
    (ìŠ¤ì¼€ì¤„ëŸ¬ìš©)
    """
    print("ðŸŒ [GLOBAL TREND] ì „ì²´ ë‰´ìŠ¤ ê¸°ë°˜ íŠ¸ë Œë“œ ìƒì„± ì‹œìž‘")

    db = SessionLocal()
    recent_news = (
        db.query(NewsFeed)
        .order_by(NewsFeed.published_at.desc())
        .limit(50)
        .all()
    )
    db.close()

    if not recent_news:
        print("âŒ ìµœê·¼ ë‰´ìŠ¤ê°€ ì—†ì–´ ì „ì—­ íŠ¸ë Œë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1) ìµœê·¼ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ìˆ˜ì§‘
    all_keywords: list[str] = []
    for n in recent_news:
        all_keywords.extend(parse_keywords(n.keywords or ""))

    # 2) ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ ëª‡ ê°œë§Œ ì„ íƒ
    #    (ì§€ê¸ˆì€ ë‹¨ìˆœížˆ ë“±ìž¥ ìˆœì„œ ê¸°ì¤€ ìƒìœ„ 5ê°œ)
    unique_keywords = list(dict.fromkeys(all_keywords))[:5]

    print("ðŸŒ ì „ì—­ íŠ¸ë Œë“œ ìƒì„± í‚¤ì›Œë“œ:", unique_keywords)

    # 3) í‚¤ì›Œë“œë³„ë¡œ ê´€ë ¨ ë‰´ìŠ¤ title ëª¨ì•„ì„œ GPT ìš”ì•½
    for keyword in unique_keywords:
        titles = [
            n.title for n in recent_news if news_has_keyword(n, keyword)
        ]

        if not titles:
            continue

        try:
            summary = generate_trend_summary(keyword, titles)
            if summary:
                save_trend_to_db(keyword, summary)
        except Exception as e:
            print(f"âš ï¸ ì „ì—­ íŠ¸ë Œë“œ ìš”ì•½ ì‹¤íŒ¨({keyword}): {e}")

    print("ðŸŒ [GLOBAL TREND] ì „ì²´ íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


# ---------------------------------------------------------
# ðŸ“Š í™ˆ í™”ë©´ ì¸ì‚¬ì´íŠ¸
# ---------------------------------------------------------
def get_ai_summary():
    """
    ìµœê·¼ ìƒì„±ëœ TechTrend 5ê°œë¥¼ ê¸°ë°˜ìœ¼ë¡œ
    í™ˆ í™”ë©´ ì¸ì‚¬ì´íŠ¸ ì¹´ë“œì— ì“¸ ë°ì´í„° ë°˜í™˜
    """
    db = SessionLocal()
    try:
        trends = (
            db.query(TechTrend)
            .order_by(TechTrend.fetched_at.desc())
            .limit(5)
            .all()
        )

        return {
            "insights": [
                {
                    "title": t.keyword,
                    "desc": (
                        t.summary[:150] + "..."
                    )
                    if len(t.summary) > 150
                    else t.summary,
                }
                for t in trends
            ]
        }
    finally:
        db.close()
